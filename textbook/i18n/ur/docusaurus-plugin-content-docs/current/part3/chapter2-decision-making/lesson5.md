---
sidebar_position: 5
sidebar_label: انسان-روبوٹ تعامل اور تعاون پر مبنی فیصلہ سازی
---

# انسان-روبوٹ تعامل اور تعاون پر مبنی فیصلہ سازی

## خلاصہ

*   **سبق 1 - Reactive Behaviors:** محرکات کے لیے بنیادی، فوری ردعمل۔
*   **سبق 2 - State-based Decision Making:** پہلے سے طے شدہ states پر مبنی منظم فیصلے۔
*   **سبق 3 - Reinforcement Learning:** آزمائش اور خطا کے ذریعے بہترین پالیسیاں سیکھنا۔
*   **سبق 4 - Motion Planning اور Pathfinding:** تصادم سے پاک حرکات اور trajectories پیدا کرنا۔

ہیومنائڈ روبوٹس تیزی سے انسانوں کے ساتھ کام کرنے کے لیے ڈیزائن کیے جا رہے ہیں، نہ صرف الگ تھلگ صنعتی ترتیبات میں، بلکہ گھروں، ہسپتالوں اور عوامی جگہوں میں۔ اس کے لیے نفیس **انسان-روبوٹ تعامل (HRI)** صلاحیتوں کی ضرورت ہوتی ہے، خاص طور پر **تعاون پر مبنی فیصلہ سازی** میں۔ خالصتاً خودمختار نظاموں کے برعکس، تعاون کرنے والے ہیومنائڈز کو انسانی ارادے کو سمجھنا، مؤثر طریقے سے بات چیت کرنا، انسانی اعمال کے مطابق ڈھلنا، اور بعض اوقات مشترکہ اہداف کو مؤثر اور محفوظ طریقے سے حاصل کرنے کے لیے کنٹرول بھی دینا ضروری ہے۔

### 1. انسانی ارادے کو سمجھنا

مؤثر تعاون کے لیے، ایک ہیومنائڈ کو یہ اندازہ لگانا ہوگا کہ اس کا انسانی ساتھی کیا کرنے کا ارادہ رکھتا ہے۔ یہ حاصل کیا جا سکتا ہے:

*   **انسانی اعمال کا مشاہدہ:** اشاروں، نظر کی سمت، جسمانی انداز، اور حرکت کے نمونوں کا تجزیہ۔ مشین لرننگ ماڈلز کو عام انسانی اعمال کو پہچاننے اور مستقبل کے اقدامات کی پیش گوئی کرنے کی تربیت دی جا سکتی ہے۔
*   **تقریر اور قدرتی زبان کی سمجھ:** بولے گئے احکامات، سوالات، اور یہاں تک کہ لسانی اشاروں کی تشریح۔ (جیسا کہ حصہ 2، باب 4، سبق 6 میں Auditory Perception پر بات کی گئی)۔
*   **سیاق و سباق کی آگاہی:** ماحول، کام، اور انسان کے سابقہ اعمال کے بارے میں علم استعمال کرتے ہوئے موجودہ ارادے کی بہتر تشریح۔ مثال کے طور پر، اگر کوئی انسان کسی آلے تک پہنچ رہا ہے، تو روبوٹ یہ اندازہ لگا سکتا ہے کہ انسان کو اس آلے کی ضرورت ہے۔

### 2. بات چیت اور وضاحت کی صلاحیت

تعاون یک طرفہ نہیں ہے؛ ہیومنائڈز کو اپنے ارادوں اور حالتوں کو بھی انسانوں کو سمجھنے کے قابل طریقے سے بتانا ضروری ہے۔

*   **زبانی بات چیت:** انسانوں سے بات کرنے کے لیے قدرتی زبان کی تخلیق استعمال کرنا۔
*   **غیر زبانی بات چیت:**
    *   **نظر:** کسی چیز کو دیکھنا تاکہ دلچسپی یا ہدف کی نشاندہی کی جا سکے۔
    *   **اشارے:** اشارہ کرنا، سر ہلانا، یا ہاتھ کی حرکات استعمال کرنا۔
    *   **جسمانی انداز:** تیاری، توجہ، یا الجھن کا اظہار کرنا۔
    *   **چہرے کے تاثرات:** سادہ robotic چہرے یا ڈسپلے بنیادی جذبات یا حالتوں کا اظہار کر سکتے ہیں۔
*   **وضاحت کے قابل AI (XAI):** پیچیدہ فیصلوں کے لیے، ہیومنائڈز کو مثالی طور پر یہ وضاحت کرنے کے قابل ہونا چاہیے کہ انہوں نے *کیوں* کوئی خاص ایکشن لیا یا کوئی مخصوص سفارش کی۔ یہ اعتماد پیدا کرتا ہے اور انسانوں کو روبوٹ کے رویے کو سمجھنے اور درست کرنے میں مدد کرتا ہے۔

### 3. موافقت پذیر کنٹرول اور مشترکہ خودمختاری

تعاون کے کاموں میں، خودمختاری کی سطح مختلف ہو سکتی ہے۔ ہیومنائڈز کو کام، انسان کی مہارت کی سطح، اور حفاظتی ضروریات کی بنیاد پر اپنی کنٹرول حکمت عملیوں کو ڈھالنا ہوگا۔

*   **مشترکہ خودمختاری:** ایک spectrum جہاں کنٹرول انسان اور روبوٹ کے درمیان مشترک ہے۔ روبوٹ کم سطح کی تکمیل (مثلاً، توازن، joint کنٹرول) سنبھال سکتا ہے، جبکہ انسان اعلیٰ سطح کی رہنمائی (مثلاً، کام کے مقاصد) فراہم کرتا ہے۔
*   **مظاہرے سے سیکھنا (LfD):** انسان جسمانی طور پر روبوٹ کی رہنمائی کر سکتے ہیں یا کاموں کا مظاہرہ کر سکتے ہیں، جس سے ہیومنائڈ کو نئی مہارتیں سیکھنے یا موجودہ مہارتوں کو بہتر بنانے کی اجازت ملتی ہے۔
*   **تعمیل اور حفاظت:** روبوٹس کو جسمانی طور پر تعمیل کے قابل ہونے کے لیے ڈیزائن کیا جانا چاہیے (مثلاً، impedance control استعمال کرتے ہوئے، جیسا کہ حصہ 2، باب 3، سبق 6 میں بات کی گئی) اور غیر متوقع انسانی رابطے پر محفوظ طریقے سے جواب دینا چاہیے۔

### 4. تعاون پر مبنی فیصلہ سازی کے فریم ورک

کئی فریم ورک رہنمائی کرتے ہیں کہ ہیومنائڈز انسانوں کے تعاون میں کیسے فیصلے کرتے ہیں:

*   **کردار کی تقسیم:** کرداروں کو متحرک طور پر تفویض کرنا (مثلاً، کون سا ذیلی کام انجام دیتا ہے، کون ایک قدم کے لیے بنیادی فیصلہ ساز ہے) صلاحیتوں اور ترجیحات کی بنیاد پر۔
*   **تنازعات کا حل:** انسان اور روبوٹ کی تجاویز کے درمیان اختلافات کو حل کرنے کے لیے طریقہ کار، شاید حفاظت سے متعلق حالات میں انسانی احکامات کو قبول کر کے یا متبادل تجویز کر کے۔
*   **مشترکہ ارادے کا اندازہ:** روبوٹ مسلسل مشترکہ ہدف اور اس کی طرف انسان کے تعاون کی سمجھ کو اپ ڈیٹ کرتا ہے۔

**کوڈ مثال (تصوراتی مشترکہ ارادے کا اندازہ):**

```python
# Conceptual Python: Simplified Joint Intent Estimation
class JointIntentEstimator:
    def __init__(self, human_skills, robot_skills, common_goals):
        self.human_skills = human_skills
        self.robot_skills = robot_skills
        self.common_goals = common_goals
        self.current_human_action = None
        self.inferred_human_intent = None
        self.shared_goal = None

    def update_human_action(self, action_observed):
        self.current_human_action = action_observed
        self._infer_human_intent()

    def _infer_human_intent(self):
        # A simple rule-based inference for illustration
        if self.current_human_action == "reaches_for_wrench" and "mechanical_repair" in self.common_goals:
            self.inferred_human_intent = "perform_mechanical_repair_step"
        elif self.current_human_action == "points_at_shelf" and "fetch_object" in self.common_goals:
            self.inferred_human_intent = "request_object_from_shelf"
        else:
            self.inferred_human_intent = "unknown"

    def propose_robot_action(self):
        if self.inferred_human_intent == "perform_mechanical_repair_step":
            if "hold_parts" in self.robot_skills:
                return "offer_to_hold_parts"
            else:
                return "standby"
        elif self.inferred_human_intent == "request_object_from_shelf":
            if "fetch_object" in self.robot_skills:
                return "fetch_indicated_object"
            else:
                return "cannot_assist"
        return "await_further_instructions"

# Example Usage
estimator = JointIntentEstimator(
    human_skills=["assemble_parts", "diagnose_issues"],
    robot_skills=["hold_parts", "fetch_object"],
    common_goals=["mechanical_repair", "fetch_object"]
)

print("Scenario 1: Human reaches for wrench during repair.")
estimator.update_human_action("reaches_for_wrench")
print(f"Inferred Human Intent: {estimator.inferred_human_intent}")
print(f"Robot's Proposed Action: {estimator.propose_robot_action()}")

print("\nScenario 2: Human points at a shelf.")
estimator.update_human_action("points_at_shelf")
print(f"Inferred Human Intent: {estimator.inferred_human_intent}")
print(f"Robot's Proposed Action: {estimator.propose_robot_action()}")
```

### HRI اور تعاون پر مبنی فیصلہ سازی میں چیلنجز

*   **انسانی اشاروں کی ابہام:** انسان ہمیشہ اپنی بات چیت میں واضح یا صریح نہیں ہوتے، جو ارادے کے اندازے کو مشکل بناتا ہے۔
*   **متحرک کردار کی تقسیم:** قیادت اور کام کی تقسیم میں اتار چڑھاؤ روبوٹس کے لیے منظم کرنا مشکل ہو سکتا ہے۔
*   **اعتماد اور قبولیت:** انسانوں کو مؤثر تعاون کے لیے روبوٹس پر اعتماد کرنے کی ضرورت ہے، جو قابل اعتماد کارکردگی، حفاظت، اور شفاف بات چیت پر بنایا جاتا ہے۔
*   **ثقافتی اختلافات:** HRI کے معیارات اور توقعات مختلف ثقافتوں میں نمایاں طور پر مختلف ہو سکتے ہیں۔
*   **اخلاقی مخمصے:** جیسے جیسے ہیومنائڈز زیادہ مربوط ہوتے جاتے ہیں، وہ تعاون کی ترتیبات میں تیزی سے پیچیدہ اخلاقی انتخابات کا سامنا کریں گے۔

### سرگرمیاں

1.  **تعاون کا مشاہدہ:** ایک سادہ کام (مثلاً، فرنیچر کا ایک ٹکڑا اکٹھا کرنا، کھانا تیار کرنا) پر تعاون کرتے ہوئے دو لوگوں کا مشاہدہ کریں۔ نوٹ کریں کہ وہ زبانی اور غیر زبانی طور پر کیسے بات چیت کرتے ہیں، اپنے اعمال کی ہم آہنگی کیسے کرتے ہیں، اور کسی بھی ابہام یا تنازعات کو کیسے حل کرتے ہیں۔ ایک روبوٹ ایسے منظر میں کیسے حصہ لے گا؟
2.  **تعاون کے کام کا ڈیزائن:** ایک سادہ تعاون کے کام کی تجویز دیں جو ایک ہیومنائڈ روبوٹ انسان کے ساتھ انجام دے سکتا ہے (مثلاً، میز لگانا، باغبانی کرنا)۔ ان مخصوص معلومات کا خاکہ بنائیں جن کی روبوٹ کو انسان سے ضرورت ہوگی، اور روبوٹ اپنے اعمال یا ضروریات کو کیسے بتائے گا۔

### ڈایاگرام

_Placeholder برائے ڈایاگرام جو ایک انسان اور ہیومنائڈ روبوٹ کے کام پر تعاون کو ظاہر کرتا ہے، تیروں کے ساتھ بات چیت کے بہاؤ (زبانی، غیر زبانی) اور مشترکہ ارادہ دکھاتے ہیں۔_
*(یہ تصویر `/static/img/diagrams/part3-ch2-lesson5-hri-collaboration.svg` میں محفوظ کی جائے گی)*

### کثیر الانتخابی سوالات

1.  خالصتاً خودمختار نظاموں اور **تعاون کرنے والے ہیومنائڈز** میں فیصلہ سازی میں کیا اہم فرق ہے؟
    a) تعاون کرنے والے ہیومنائڈز کبھی اپنے طور پر فیصلے نہیں کرتے۔
    b) تعاون کرنے والے ہیومنائڈز کو انسانی ارادے کو سمجھنا اور انسانی اعمال کے مطابق ڈھلنا ضروری ہے۔
    c) خودمختار نظام ہمیشہ تعاون کرنے والے سے زیادہ محفوظ ہوتے ہیں۔
    d) تعاون کرنے والے ہیومنائڈز صرف سادہ، تکراری کام انجام دیتے ہیں۔
    **جواب: b**

2.  ہیومنائڈ **انسانی ارادے کو سمجھنے** کے لیے کون سے طریقے استعمال کر سکتا ہے؟
    a) بے ترتیب اندازہ لگانا کہ انسان کیا چاہتا ہے۔
    b) انسانی اشاروں، نظر کی سمت، اور تقریر کا تجزیہ کرنا۔
    c) انسانی ان پٹ کو نظر انداز کرنا اور صرف اپنی پروگرامنگ پر انحصار کرنا۔
    d) صرف براہ راست تحریری احکامات کا جواب دینا۔
    **جواب: b**

3.  HRI میں **وضاحت کے قابل AI (XAI)** کا مقصد ہے:
    a) روبوٹس کو زیادہ انسان نما بنانا۔
    b) روبوٹس کو یہ وضاحت کرنے کی اجازت دینا کہ انہوں نے *کیوں* کوئی خاص ایکشن لیا یا سفارش کی۔
    c) روبوٹ کی جسمانی طاقت بڑھانا۔
    d) انسانی نگرانی کی ضرورت کو کم کرنا۔
    **جواب: b**

4.  **مشترکہ خودمختاری** ایک ایسی صورتحال کی طرف اشارہ کرتی ہے جہاں:
    a) روبوٹ تمام کاموں پر مکمل کنٹرول رکھتا ہے۔
    b) انسان تمام کاموں پر مکمل کنٹرول رکھتا ہے۔
    c) کنٹرول تقسیم اور انسان اور روبوٹ کے درمیان مشترک ہے۔
    d) روبوٹ بغیر کسی انسانی مداخلت کے کام کرتا ہے۔
    **جواب: c**

5.  ان میں سے کون سے غیر زبانی اشارے ایک ہیومنائڈ روبوٹ اپنے ارادوں کو بتانے کے لیے استعمال کر سکتا ہے؟
    a) اپنی اندرونی گھڑی کی ترتیبات تبدیل کرنا۔
    b) اپنی بجلی کی کھپت کو ایڈجسٹ کرنا۔
    c) نظر، اشارے، اور جسمانی انداز۔
    d) پرانی log files کو حذف کرنا۔
    **جواب: c**

6.  **انسان-روبوٹ تعامل (HRI)** میں ایک بڑا چیلنج انسانی اشاروں کی ابہام ہے کیونکہ:
    a) روبوٹس انسانوں سے جسمانی طور پر کمزور ہوتے ہیں۔
    b) انسان ہمیشہ اپنی بات چیت میں بالکل واضح اور صریح ہوتے ہیں۔
    c) انسان ہمیشہ واضح یا صریح نہیں ہوتے، جو ارادے کے اندازے کو مشکل بناتا ہے۔
    d) روبوٹس بصری معلومات پر کارروائی نہیں کر سکتے۔
    **جواب: c**

7.  ہیومنائڈز میں **تعمیل**، خاص طور پر جسمانی تعامل کے دوران، اشارہ کرتی ہے:
    a) پیچیدہ زبانی احکامات پر عمل کرنے کی ان کی صلاحیت۔
    b) جسمانی رابطے کے مطابق اپنی حرکات کو ڈھالنے، محفوظ طریقے سے جھکنے کی صلاحیت۔
    c) اخلاقی رہنما خطوط کی پابندی۔
    d) بھاری اشیاء اٹھانے کی صلاحیت۔
    **جواب: b**

8.  ہیومنائڈ روبوٹ کے **مظاہرے سے سیکھنا (LfD)** استعمال کرنے کا فائدہ کیا ہے؟
    a) یہ روبوٹ کو پیچیدہ اخلاقی تحفظات کو نظرانداز کرنے کی اجازت دیتا ہے۔
    b) یہ انسانوں کو روبوٹ کو نئی مہارتیں سکھانے یا موجودہ مہارتوں کو بہتر بنانے کی اجازت دیتا ہے۔
    c) یہ روبوٹ کے ہارڈ ویئر ڈیزائن کو آسان بناتا ہے۔
    d) یہ روبوٹ کی توانائی کی کھپت کو کم کرتا ہے۔
    **جواب: b**

9.  جب ایک ہیومنائڈ کو ایک بوڑھے شخص کی مدد کرنے کے لیے ڈیزائن کیا گیا ہے، تو HRI میں **حفاظت** سب سے اہم ہے۔ ان میں سے کیا اہم ہے؟
    a) روبوٹ کی رفتار کو زیادہ سے زیادہ کرنا۔
    b) اس بات کو یقینی بنانا کہ روبوٹ زیادہ طاقت کا استعمال نہیں کرتا یا نقصان نہیں پہنچاتا۔
    c) مسلسل نگرانی کے لیے روبوٹ کو بہت سے کیمروں سے لیس کرنا۔
    d) روبوٹ کی حرکات کو غیر متوقع بنانا۔
    **جواب: b**

10. تعاون پر مبنی فیصلہ سازی میں **"مشترکہ ارادے کا اندازہ"** سے کیا مراد ہے؟
    a) روبوٹ اندازہ لگانا کہ انسان آگے کیا کرنا چاہتا ہے۔
    b) روبوٹ انسان سے مشورہ کیے بغیر تمام فیصلے کرنا۔
    c) روبوٹ مسلسل مشترکہ ہدف اور انسان کے تعاون کی سمجھ کو اپ ڈیٹ کرنا۔
    d) کارکردگی کے لیے روبوٹ انسانی احکامات کو override کرنا۔
    **جواب: c**

### ڈایاگرام

_Placeholder برائے ڈایاگرام جو ایک انسان اور ہیومنائڈ روبوٹ کے کام پر تعاون کو ظاہر کرتا ہے، تیروں کے ساتھ بات چیت کے بہاؤ (زبانی، غیر زبانی) اور مشترکہ ارادہ دکھاتے ہیں۔_
*(یہ تصویر `/static/img/diagrams/part3-ch2-lesson5-hri-collaboration.svg` میں محفوظ کی جائے گی)*
